
@misc{yuta-hi_yuta-hibayesian_unet_2021,
	title = {yuta-hi/bayesian\_unet},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/yuta-hi/bayesian_unet},
	abstract = {Chainer implementation of Bayesian Convolutional Neural Networks (BCNNs)},
	urldate = {2021-03-16},
	author = {yuta-hi},
	month = mar,
	year = {2021},
	note = {original-date: 2019-09-06T05:07:26Z},
	keywords = {adversarial-training, bayesian, chainer, cnn, pix2pix, uncertainty, unet},
}

@misc{labonte_deep_2020,
	title = {Deep {Learning} {Segmentation} with {Uncertainty} via {3D} {Bayesian} {Convolutional} {Neural} {Networks}},
	url = {https://towardsdatascience.com/deep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7277b078},
	abstract = {How can neural networks learn probability distributions to quantify uncertainty in their predictions?},
	language = {en},
	urldate = {2021-03-16},
	journal = {Medium},
	author = {LaBonte, Tyler},
	month = mar,
	year = {2020},
	file = {Snapshot:files/134/deep-learning-segmentation-with-uncertainty-via-3d-bayesian-convolutional-neural-networks-6b1c7.html:text/html},
}

@incollection{chung_bayesian_2019,
	address = {Cham},
	title = {A {Bayesian} {Neural} {Net} to {Segment} {Images} with {Uncertainty} {Estimates} and {Good} {Calibration}},
	volume = {11492},
	isbn = {978-3-030-20350-4 978-3-030-20351-1},
	url = {http://link.springer.com/10.1007/978-3-030-20351-1_1},
	abstract = {We propose a novel Bayesian decision theoretic deep-neuralnetwork (DNN) framework for image segmentation, enabling us to deﬁne a principled measure of uncertainty associated with label probabilities. Our framework estimates uncertainty analytically at test time, unlike the state of the art that relies on approximate and expensive algorithms using sampling or multiple passes. Moreover, our framework leads to a novel Bayesian interpretation of the softmax layer. We propose a novel method to improve DNN calibration. Results on three large datasets show that our framework improves segmentation quality and calibration, and provides more realistic uncertainty estimates, over existing methods.},
	language = {en},
	urldate = {2021-03-16},
	booktitle = {Information {Processing} in {Medical} {Imaging}},
	publisher = {Springer International Publishing},
	author = {Jena, Rohit and Awate, Suyash P.},
	editor = {Chung, Albert C. S. and Gee, James C. and Yushkevich, Paul A. and Bao, Siqi},
	year = {2019},
	doi = {10.1007/978-3-030-20351-1_1},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {3--15},
	file = {Jena et Awate - 2019 - A Bayesian Neural Net to Segment Images with Uncer.pdf:files/135/Jena et Awate - 2019 - A Bayesian Neural Net to Segment Images with Uncer.pdf:application/pdf},
}

@article{pereyra_fast_2016,
	title = {Fast unsupervised {Bayesian} image segmentation with adaptive spatial regularisation},
	url = {http://arxiv.org/abs/1502.01400},
	abstract = {This paper presents a new Bayesian estimation technique for hidden Potts-Markov random ﬁelds with unknown regularisation parameters, with application to fast unsupervised K-class image segmentation. The technique is derived by ﬁrst removing the regularisation parameter from the Bayesian model by marginalisation, followed by a small-variance-asymptotic (SVA) analysis in which the spatial regularisation and the integer-constrained terms of the Potts model are decoupled. The evaluation of this SVA Bayesian estimator is then relaxed into a problem that can be computed efﬁciently by iteratively solving a convex total-variation denoising problem and a least-squares clustering (K-means) problem, both of which can be solved straightforwardly, even in high-dimensions, and with parallel computing techniques. This leads to a fast fully unsupervised Bayesian image segmentation methodology in which the strength of the spatial regularisation is adapted automatically to the observed image during the inference procedure, and that can be easily applied in large 2D and 3D scenarios or in applications requiring low computing times. Experimental results on real images, as well as extensive comparisons with state-of-the-art algorithms, conﬁrm that the proposed methodology offer extremely fast convergence and produces accurate segmentation results, with the important additional advantage of self-adjusting regularisation parameters.},
	language = {en},
	urldate = {2021-03-16},
	journal = {arXiv:1502.01400 [cs, stat]},
	author = {Pereyra, Marcelo and McLaughlin, Steve},
	month = feb,
	year = {2016},
	note = {arXiv: 1502.01400},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Computation},
	file = {Pereyra et McLaughlin - 2016 - Fast unsupervised Bayesian image segmentation with.pdf:files/137/Pereyra et McLaughlin - 2016 - Fast unsupervised Bayesian image segmentation with.pdf:application/pdf},
}

@article{ozdemir_active_2019,
	title = {Active {Learning} for {Segmentation} {Based} on {Bayesian} {Sample} {Queries}},
	url = {http://arxiv.org/abs/1912.10493},
	abstract = {Segmentation of anatomical structures is a fundamental image analysis task for many applications in the medical ﬁeld. Deep learning methods have been shown to perform well, but for this purpose large numbers of manual annotations are needed in the ﬁrst place, which necessitate prohibitive levels of resources that are often unavailable. In an active learning framework of selecting informed samples for manual labeling, expert clinician time for manual annotation can be optimally utilized, enabling the establishment of large labeled datasets for machine learning. In this paper, we propose a novel method that combines representativeness with uncertainty in order to estimate ideal samples to be annotated, iteratively from a given dataset. Our novel representativeness metric is based on Bayesian sampling, by using information-maximizing autoencoders. We conduct experiments on a shoulder magnetic resonance imaging (MRI) dataset for the segmentation of four musculoskeletal tissue classes. Quantitative results show that the annotation of representative samples selected by our proposed querying method yields an improved segmentation performance at each active learning iteration, compared to a baseline method that also employs uncertainty and representativeness metrics. For instance, with only 10\% of the dataset annotated, our method reaches within 5\% of Dice score expected from the upper bound scenario of all the dataset given as annotated (an impractical scenario due to resource constraints), and this gap drops down to a mere 2\% when less than a ﬁfth of the dataset samples are annotated. Such active learning approach to selecting samples to annotate enables an optimal use of the expert clinician time, being often the bottleneck in realizing machine learning solutions in medicine.},
	language = {en},
	urldate = {2021-03-16},
	journal = {arXiv:1912.10493 [cs]},
	author = {Ozdemir, Firat and Peng, Zixuan and Fuernstahl, Philipp and Tanner, Christine and Goksel, Orcun},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.10493},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: 10 pages, 7 figures},
	file = {Ozdemir et al. - 2019 - Active Learning for Segmentation Based on Bayesian.pdf:files/139/Ozdemir et al. - 2019 - Active Learning for Segmentation Based on Bayesian.pdf:application/pdf},
}

@article{schiewe_segmentation_nodate,
	title = {{SEGMENTATION} {OF} {HIGH}-{RESOLUTION} {REMOTELY} {SENSED} {DATA} -  {CONCEPTS}, {APPLICATIONS} {AND} {PROBLEMS}},
	abstract = {Segmentation algorithms have already been recognized as a valuable and complementary approach that similar to human operators perform a region-based rather than a point-based evaluation of high-resolution and multi-source remotely sensed data. Goal of this paper is to summarize the state-of-the-art of respective segmentation methods by describing the underlying concepts which are rather complex in the case of processing remotely sensed data, demonstrating various applications (automatical object recognition, signalbased fusion as support for visual interpretation, and estimation of the terrain surface from Digital Surface Models), and identifying yet existing problems and further research and development needs.},
	language = {en},
	author = {Schiewe, J},
	pages = {6},
	file = {Schiewe - SEGMENTATION OF HIGH-RESOLUTION REMOTELY SENSED DA.pdf:files/143/Schiewe - SEGMENTATION OF HIGH-RESOLUTION REMOTELY SENSED DA.pdf:application/pdf},
}

@inproceedings{heller_bayesian_2005,
	address = {Bonn, Germany},
	title = {Bayesian hierarchical clustering},
	isbn = {978-1-59593-180-1},
	url = {http://portal.acm.org/citation.cfm?doid=1102351.1102389},
	doi = {10.1145/1102351.1102389},
	abstract = {We present a novel algorithm for agglomerative hierarchical clustering based on evaluating marginal likelihoods of a probabilistic model. This algorithm has several advantages over traditional distance-based agglomerative clustering algorithms. (1) It deﬁnes a probabilistic model of the data which can be used to compute the predictive distribution of a test point and the probability of it belonging to any of the existing clusters in the tree. (2) It uses a model-based criterion to decide on merging clusters rather than an ad-hoc distance metric. (3) Bayesian hypothesis testing is used to decide which merges are advantageous and to output the recommended depth of the tree. (4) The algorithm can be interpreted as a novel fast bottom-up approximate inference method for a Dirichlet process (i.e. countably inﬁnite) mixture model (DPM). It provides a new lower bound on the marginal likelihood of a DPM by summing over exponentially many clusterings of the data in polynomial time. We describe procedures for learning the model hyperparameters, computing the predictive distribution, and extensions to the algorithm. Experimental results on synthetic and real-world data sets demonstrate useful properties of the algorithm.},
	language = {en},
	urldate = {2021-03-16},
	booktitle = {Proceedings of the 22nd international conference on {Machine} learning  - {ICML} '05},
	publisher = {ACM Press},
	author = {Heller, Katherine A. and Ghahramani, Zoubin},
	year = {2005},
	pages = {297--304},
	file = {Heller et Ghahramani - 2005 - Bayesian hierarchical clustering.pdf:files/145/Heller et Ghahramani - 2005 - Bayesian hierarchical clustering.pdf:application/pdf},
}

@article{kraus_automatic_nodate,
	title = {{AUTOMATIC} {DEM} {GENERATION} {AND} {3D} {CHANGE} {DETECTION} {FROM} {SATELLITE} {IMAGERY}},
	abstract = {In this paper we present a method for fully automatic generation of digital surface models (DSM) from very high resolution (VHR) satellite imagery and the consecutively automatic change detection from the derived 3D information.},
	language = {en},
	author = {Krauß, Thomas},
	pages = {8},
	annote = {Robust difference pour supprimer les bruits potentiel lié à l'utilisation de différents capteurs},
	file = {Krauß - AUTOMATIC DEM GENERATION AND 3D CHANGE DETECTION F.pdf:files/147/Krauß - AUTOMATIC DEM GENERATION AND 3D CHANGE DETECTION F.pdf:application/pdf},
}

@inproceedings{tian_multitemporal_2011,
	address = {Tengchong, Yunnan, China},
	title = {Multitemporal {3D} {Change} {Detection} in {Urban} {Areas} {Using} {Stereo} {Information} from {Different} {Sensors}},
	isbn = {978-1-4577-0967-8},
	url = {http://ieeexplore.ieee.org/document/6024215/},
	doi = {10.1109/ISIDF.2011.6024215},
	language = {en},
	urldate = {2021-03-17},
	booktitle = {2011 {International} {Symposium} on {Image} and {Data} {Fusion}},
	publisher = {IEEE},
	author = {Tian, Jiaojiao and Reinartz, Peter},
	month = aug,
	year = {2011},
	pages = {1--4},
	annote = {Utilisation d'un extracteur d'ombre pour ensuite rafiner l'extractiion du building
 },
	file = {Tian et Reinartz - 2011 - Multitemporal 3D Change Detection in Urban Areas U.pdf:files/149/Tian et Reinartz - 2011 - Multitemporal 3D Change Detection in Urban Areas U.pdf:application/pdf},
}

@article{chaabouni-chouayakh_multi-spectral_nodate,
	title = {Multi-spectral and {Digital} {Elevation} {Model} {Information} {Fusion} for {Automatic} {3D} {Change} {Detection}},
	language = {en},
	author = {Chaabouni-Chouayakh, Houda and Arnau, Isabel Rodes and Reinartz, Peter},
	pages = {15},
	file = {Chaabouni-Chouayakh et al. - Multi-spectral and Digital Elevation Model Informa.pdf:files/153/Chaabouni-Chouayakh et al. - Multi-spectral and Digital Elevation Model Informa.pdf:application/pdf},
}

@article{chaabouni-chouayakh_towards_2013,
	title = {Towards automatic 3-{D} change detection through multi-spectral and digital elevation model information fusion},
	volume = {4},
	issn = {1947-9832, 1947-9824},
	url = {http://www.tandfonline.com/doi/abs/10.1080/19479832.2012.739577},
	doi = {10.1080/19479832.2012.739577},
	language = {en},
	number = {1},
	urldate = {2021-03-17},
	journal = {International Journal of Image and Data Fusion},
	author = {Chaabouni-Chouayakh, Houda and Arnau, Isabel Rodes and Reinartz, Peter},
	month = mar,
	year = {2013},
	pages = {89--101},
	annote = {3D change detection with mutli spectral data fusion : Multi spectral, Pan et DEM},
	file = {Chaabouni-Chouayakh et al. - 2013 - Towards automatic 3-D change detection through mul.pdf:files/155/Chaabouni-Chouayakh et al. - 2013 - Towards automatic 3-D change detection through mul.pdf:application/pdf},
}

@article{arnau_multispectral_nodate,
	title = {Multispectral and {Digital} {Elevation} {Model} {Information} {Fusion} for {Classiﬁcation} and {Change} {Detection} in {Earth} {Observation}},
	language = {en},
	author = {Arnau, Isabel Rodes},
	pages = {87},
	file = {Arnau - Multispectral and Digital Elevation Model Informat.pdf:files/158/Arnau - Multispectral and Digital Elevation Model Informat.pdf:application/pdf},
}

@article{shi_change_2020,
	title = {Change {Detection} {Based} on {Artificial} {Intelligence}: {State}-of-the-{Art} and {Challenges}},
	volume = {12},
	issn = {2072-4292},
	shorttitle = {Change {Detection} {Based} on {Artificial} {Intelligence}},
	url = {https://www.mdpi.com/2072-4292/12/10/1688},
	doi = {10.3390/rs12101688},
	abstract = {Change detection based on remote sensing (RS) data is an important method of detecting changes on the Earth’s surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision. In recent years, integrated artiﬁcial intelligence (AI) technology has become a research focus in developing new change detection methods. Although some researchers claim that AI-based change detection approaches outperform traditional change detection approaches, it is not immediately obvious how and to what extent AI can improve the performance of change detection. This review focuses on the state-of-the-art methods, applications, and challenges of AI for change detection. Speciﬁcally, the implementation process of AI-based change detection is ﬁrst introduced. Then, the data from diﬀerent sensors used for change detection, including optical RS data, synthetic aperture radar (SAR) data, street view images, and combined heterogeneous data, are presented, and the available open datasets are also listed. The general frameworks of AI-based change detection methods are reviewed and analyzed systematically, and the unsupervised schemes used in AI-based change detection are further analyzed. Subsequently, the commonly used networks in AI for change detection are described. From a practical point of view, the application domains of AI-based change detection methods are classiﬁed based on their applicability. Finally, the major challenges and prospects of AI for change detection are discussed and delineated, including (a) heterogeneous big data processing, (b) unsupervised AI, and (c) the reliability of AI. This review will be beneﬁcial for researchers in understanding this ﬁeld.},
	language = {en},
	number = {10},
	urldate = {2021-03-17},
	journal = {Remote Sensing},
	author = {Shi, Wenzhong and Zhang, Min and Zhang, Rui and Chen, Shanxiong and Zhan, Zhao},
	month = may,
	year = {2020},
	pages = {1688},
	file = {Shi et al. - 2020 - Change Detection Based on Artificial Intelligence.pdf:files/160/Shi et al. - 2020 - Change Detection Based on Artificial Intelligence.pdf:application/pdf},
}

@inproceedings{zhao_deep_2014,
	title = {Deep learning to classify difference image for image change detection},
	doi = {10.1109/IJCNN.2014.6889510},
	abstract = {Image change detection is a process to analyze multi-temproal images of the same scene for identifying the changes that have occurred. In this paper, we propose a novel difference image analysis approach based on deep neural networks for image change detection problems. The deep neural network learning algorithm for classification includes unsupervised feature learning and supervised fine-tuning. Some samples with the labels of high accuracy obtained by a pre-classification are used for fine-tuning. Since a deep neural network can learn complicated functions that can represent high-level abstractions, it can obtain satisfactory results. Theoretical analysis and experiment results on real datasets show that the proposed method outperforms some other methods.},
	author = {Zhao, Jiaojiao and Gong, Maoguo and Liu, Jia and Jiao, Licheng},
	month = jul,
	year = {2014},
	pages = {411--417},
	file = {Full Text PDF:files/163/Zhao et al. - 2014 - Deep learning to classify difference image for ima.pdf:application/pdf},
}

@article{xu_advanced_2019,
	title = {Advanced {Multi}-{Sensor} {Optical} {Remote} {Sensing} for {Urban} {Land} {Use} and {Land} {Cover} {Classification}: {Outcome} of the 2018 {IEEE} {GRSS} {Data} {Fusion} {Contest}},
	volume = {12},
	issn = {1939-1404, 2151-1535},
	shorttitle = {Advanced {Multi}-{Sensor} {Optical} {Remote} {Sensing} for {Urban} {Land} {Use} and {Land} {Cover} {Classification}},
	url = {https://ieeexplore.ieee.org/document/8727489/},
	doi = {10.1109/JSTARS.2019.2911113},
	abstract = {This paper presents the scientiﬁc outcomes of the 2018 Data Fusion Contest organized by the Image Analysis and Data Fusion Technical Committee of the IEEE Geoscience and Remote Sensing Society. The 2018 Contest addressed the problem of urban observation and monitoring with advanced multisource optical remote sensing (multispectral LiDAR, hyperspectral imaging, and very-high-resolution imagery). The competition was based on urban land use and land cover classiﬁcation aiming to distinguish between very diverse and detailed classes of urban objects, materials, and vegetation. Besides data fusion, it also quantiﬁed the respective assets of the novel sensors used to collect the data. Participants proposed elaborate approaches rooted in remote-sensing but also in machine learning and computer vision to make the most of the available data. Winning approaches combine convolutional neural networks with subtle Earth-observation data scientist expertise.},
	language = {en},
	number = {6},
	urldate = {2021-03-17},
	journal = {IEEE J. Sel. Top. Appl. Earth Observations Remote Sensing},
	author = {Xu, Yonghao and Du, Bo and Zhang, Liangpei and Cerra, Daniele and Pato, Miguel and Carmona, Emiliano and Prasad, Saurabh and Yokoya, Naoto and Hansch, Ronny and Le Saux, Bertrand},
	month = jun,
	year = {2019},
	pages = {1709--1724},
	file = {Xu et al. - 2019 - Advanced Multi-Sensor Optical Remote Sensing for U.pdf:files/165/Xu et al. - 2019 - Advanced Multi-Sensor Optical Remote Sensing for U.pdf:application/pdf},
}

@article{li_deep_2020,
	title = {Deep learning-based approach for landform classification from integrated data sources of digital elevation model and imagery},
	volume = {354},
	doi = {10.1016/j.geomorph.2020.107045},
	journal = {Geomorphology},
	author = {Li, Sijin and Xiong, LiYang and Tang, Guoan and Strobl, Josef},
	month = apr,
	year = {2020},
	pages = {107045},
}

@article{hamaguchi_rare_2018,
	title = {Rare {Event} {Detection} using {Disentangled} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1812.01285},
	abstract = {This paper presents a novel method for rare event detection from an image pair with class-imbalanced datasets. A straightforward approach for event detection tasks is to train a detection network from a large-scale dataset in an end-to-end manner. However, in many applications such as building change detection on satellite images, few positive samples are available for the training. Moreover, scene image pairs contain many trivial events, such as in illumination changes or background motions. These many trivial events and the class imbalance problem lead to false alarms for rare event detection. In order to overcome these difﬁculties, we propose a novel method to learn disentangled representations from only low-cost negative samples. The proposed method disentangles different aspects in a pair of observations: variant and invariant factors that represent trivial events and image contents, respectively. The effectiveness of the proposed approach is veriﬁed by the quantitative evaluations on four change detection datasets, and the qualitative analysis shows that the proposed method can acquire the representations that disentangle rare events from trivial ones.},
	language = {en},
	urldate = {2021-04-08},
	journal = {arXiv:1812.01285 [cs]},
	author = {Hamaguchi, Ryuhei and Sakurada, Ken and Nakamura, Ryosuke},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.01285},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Hamaguchi et al. - 2018 - Rare Event Detection using Disentangled Representa.pdf:files/181/Hamaguchi et al. - 2018 - Rare Event Detection using Disentangled Representa.pdf:application/pdf},
}

@article{hamaguchi_rare_2018-1,
	title = {Rare {Event} {Detection} using {Disentangled} {Representation} {Learning}},
	url = {http://arxiv.org/abs/1812.01285},
	abstract = {This paper presents a novel method for rare event detection from an image pair with class-imbalanced datasets. A straightforward approach for event detection tasks is to train a detection network from a large-scale dataset in an end-to-end manner. However, in many applications such as building change detection on satellite images, few positive samples are available for the training. Moreover, scene image pairs contain many trivial events, such as in illumination changes or background motions. These many trivial events and the class imbalance problem lead to false alarms for rare event detection. In order to overcome these difﬁculties, we propose a novel method to learn disentangled representations from only low-cost negative samples. The proposed method disentangles different aspects in a pair of observations: variant and invariant factors that represent trivial events and image contents, respectively. The effectiveness of the proposed approach is veriﬁed by the quantitative evaluations on four change detection datasets, and the qualitative analysis shows that the proposed method can acquire the representations that disentangle rare events from trivial ones.},
	language = {en},
	urldate = {2021-04-08},
	journal = {arXiv:1812.01285 [cs]},
	author = {Hamaguchi, Ryuhei and Sakurada, Ken and Nakamura, Ryosuke},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.01285},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Hamaguchi et al. - 2018 - Rare Event Detection using Disentangled Representa.pdf:files/183/Hamaguchi et al. - 2018 - Rare Event Detection using Disentangled Representa.pdf:application/pdf},
}
